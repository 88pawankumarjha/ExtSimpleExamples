{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Binary Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/88pawankumarjha/ExtSimpleExamples/blob/master/Copy_of_Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGXua-qoYy-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d8d1ff4-9436-42c2-efe3-c64e7cf40866"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, SimpleRNN, Dense\n",
        "import keras.backend as K\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqRcbCnOkC6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "e8351564-20e6-49c2-bdad-8e8a705a7ba4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD07h9eHY4Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the data\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/tf2.0/sbux.csv')\n",
        "df = pd.read_csv('/content/drive/My Drive/projects/bofa/python/CIPLA.NS.csv', error_bad_lines=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLzNOpYuY6Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "b3c25544-d6da-4598-a64a-be6f8ac32de4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29-07-2019</td>\n",
              "      <td>531.599976</td>\n",
              "      <td>534.950012</td>\n",
              "      <td>520.250000</td>\n",
              "      <td>522.250000</td>\n",
              "      <td>735045.0</td>\n",
              "      <td>CIPLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30-07-2019</td>\n",
              "      <td>522.200012</td>\n",
              "      <td>533.599976</td>\n",
              "      <td>517.799988</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>1665158.0</td>\n",
              "      <td>CIPLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31-07-2019</td>\n",
              "      <td>516.900024</td>\n",
              "      <td>522.700012</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>521.099976</td>\n",
              "      <td>1828077.0</td>\n",
              "      <td>CIPLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01-08-2019</td>\n",
              "      <td>516.150024</td>\n",
              "      <td>519.450012</td>\n",
              "      <td>509.200012</td>\n",
              "      <td>512.450012</td>\n",
              "      <td>1289007.0</td>\n",
              "      <td>CIPLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02-08-2019</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>519.700012</td>\n",
              "      <td>508.700012</td>\n",
              "      <td>516.099976</td>\n",
              "      <td>1574251.0</td>\n",
              "      <td>CIPLA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date        Open        High         Low       Close     Volume   Name\n",
              "0  29-07-2019  531.599976  534.950012  520.250000  522.250000   735045.0  CIPLA\n",
              "1  30-07-2019  522.200012  533.599976  517.799988  520.000000  1665158.0  CIPLA\n",
              "2  31-07-2019  516.900024  522.700012  506.000000  521.099976  1828077.0  CIPLA\n",
              "3  01-08-2019  516.150024  519.450012  509.200012  512.450012  1289007.0  CIPLA\n",
              "4  02-08-2019  509.000000  519.700012  508.700012  516.099976  1574251.0  CIPLA"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kLqFQ0-Y9Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate returns by first shifting the data\n",
        "df['PrevClose'] = df['Close'].shift(1) # move everything up 1\n",
        " \n",
        "# so now it's like\n",
        "# close / prev close\n",
        "# x[2] x[1]\n",
        "# x[3] x[2]\n",
        "# x[4] x[3]\n",
        "# ...\n",
        "# x[t] x[t-1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbVYCAdoY97B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# then the return is\n",
        "# (x[t] - x[t-1]) / x[t-1]\n",
        "df['Return'] = (df['Close'] - df['PrevClose']) / df['PrevClose']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GWGmHRvZAKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "f0d78594-8433-4276-c219-8b3aa7901db6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Name</th>\n",
              "      <th>PrevClose</th>\n",
              "      <th>Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29-07-2019</td>\n",
              "      <td>531.599976</td>\n",
              "      <td>534.950012</td>\n",
              "      <td>520.250000</td>\n",
              "      <td>522.250000</td>\n",
              "      <td>735045.0</td>\n",
              "      <td>CIPLA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30-07-2019</td>\n",
              "      <td>522.200012</td>\n",
              "      <td>533.599976</td>\n",
              "      <td>517.799988</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>1665158.0</td>\n",
              "      <td>CIPLA</td>\n",
              "      <td>522.250000</td>\n",
              "      <td>-0.004308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31-07-2019</td>\n",
              "      <td>516.900024</td>\n",
              "      <td>522.700012</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>521.099976</td>\n",
              "      <td>1828077.0</td>\n",
              "      <td>CIPLA</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>0.002115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01-08-2019</td>\n",
              "      <td>516.150024</td>\n",
              "      <td>519.450012</td>\n",
              "      <td>509.200012</td>\n",
              "      <td>512.450012</td>\n",
              "      <td>1289007.0</td>\n",
              "      <td>CIPLA</td>\n",
              "      <td>521.099976</td>\n",
              "      <td>-0.016599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02-08-2019</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>519.700012</td>\n",
              "      <td>508.700012</td>\n",
              "      <td>516.099976</td>\n",
              "      <td>1574251.0</td>\n",
              "      <td>CIPLA</td>\n",
              "      <td>512.450012</td>\n",
              "      <td>0.007123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date        Open        High  ...   Name   PrevClose    Return\n",
              "0  29-07-2019  531.599976  534.950012  ...  CIPLA         NaN       NaN\n",
              "1  30-07-2019  522.200012  533.599976  ...  CIPLA  522.250000 -0.004308\n",
              "2  31-07-2019  516.900024  522.700012  ...  CIPLA  520.000000  0.002115\n",
              "3  01-08-2019  516.150024  519.450012  ...  CIPLA  521.099976 -0.016599\n",
              "4  02-08-2019  509.000000  519.700012  ...  CIPLA  512.450012  0.007123\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0na4SSfZDp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now turn the full data into numpy arrays\n",
        " \n",
        "# Not yet in the final \"X\" format!\n",
        "input_data = df[['Open', 'High', 'Low', 'Close', 'Volume']].values\n",
        "targets = df['Return'].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0u9xJ5iZEwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Ntrain to two-thirds of the dataset\n",
        "# N = len(input_data) - T\n",
        "# Ntrain = N * 2 // 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pTXf4AxgKWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set number of prev. time steps to use\n",
        "T = 10\n",
        " \n",
        "# Set input dimensionality\n",
        "D = input_data.shape[1]\n",
        " \n",
        "# Set Ntrain to two-thirds of the dataset\n",
        "N = len(input_data) - T\n",
        "Ntrain = N * 2 // 3"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rorls1Wf-I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_train = input_data[:Ntrain + T - 1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTIBE4GagT2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(input_data_train)\n",
        "input_data = scaler.transform(input_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVGlcqI-gvLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup X_train and Y_train\n",
        "X_train = np.zeros((Ntrain, T, D))\n",
        "Y_train = np.zeros(Ntrain)\n",
        " \n",
        "for t in range(Ntrain):\n",
        "  X_train[t, :, :] = input_data[t:t+T]\n",
        "  Y_train[t] = (targets[t+T] > 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3-dNJ0g7V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup X_test and Y_test\n",
        "X_test = np.zeros((N - Ntrain, T, D))\n",
        "Y_test = np.zeros(N - Ntrain)\n",
        " \n",
        "for u in range(N - Ntrain):\n",
        "  # u counts from 0...(N - Ntrain)\n",
        "  # t counts from Ntrain...N\n",
        "  t = u + Ntrain\n",
        "  X_test[u, :, :] = input_data[t:t+T]\n",
        "  Y_test[u] = (targets[t+T] > 0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rRm1SKlhXJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make the RNN\n",
        "i = Input(shape=(T, D))\n",
        "x = LSTM(50)(i)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(i, x)\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=Adam(lr=0.001),\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU16Cj_AhZls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4e47dba-eb6c-4b14-917f-b095d4cb1072"
      },
      "source": [
        "# train the RNN\n",
        "r = model.fit(\n",
        "  X_train, Y_train,\n",
        "  batch_size=32,\n",
        "  epochs=300,\n",
        "  validation_data=(X_test, Y_test),\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 156 samples, validate on 79 samples\n",
            "Epoch 1/300\n",
            "156/156 [==============================] - 2s 14ms/step - loss: nan - accuracy: 0.0897 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 11/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 12/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 13/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 14/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 15/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 16/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 17/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 18/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 19/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 20/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 21/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 22/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 23/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 24/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 25/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 26/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 27/300\n",
            "156/156 [==============================] - 0s 998us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 28/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 29/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 30/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 31/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 32/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 33/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 34/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 35/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 36/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 37/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 38/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 39/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 40/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 41/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 42/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 43/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 44/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 45/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 46/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 47/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 48/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 49/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 50/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 51/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 52/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 53/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 54/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 55/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 56/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 57/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 58/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 59/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 60/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 61/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 62/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 63/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 64/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 65/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 66/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 67/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 68/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 69/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 70/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 71/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 72/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 73/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 74/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 75/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 76/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 77/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 78/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 79/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 80/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 81/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 82/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 83/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 84/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 85/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 86/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 87/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 88/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 89/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 90/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 91/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 92/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 93/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 94/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 95/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 96/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 97/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 98/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 99/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 100/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 101/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 102/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 103/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 104/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 105/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 106/300\n",
            "156/156 [==============================] - 0s 996us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 107/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 108/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 109/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 110/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 111/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 112/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 113/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 114/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 115/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 116/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 117/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 118/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 119/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 120/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 121/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 122/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 123/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 124/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 125/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 126/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 127/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 128/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 129/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 130/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 131/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 132/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 133/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 134/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 135/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 136/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 137/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 138/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 139/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 140/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 141/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 142/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 143/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 144/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 145/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 146/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 147/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 148/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 149/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 150/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 151/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 152/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 153/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 154/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 155/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 156/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 157/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 158/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 159/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 160/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 161/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 162/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 163/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 164/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 165/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 166/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 167/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 168/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 169/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 170/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 171/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 172/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 173/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 174/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 175/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 176/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 177/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 178/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 179/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 180/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 181/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 182/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 183/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 184/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 185/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 186/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 187/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 188/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 189/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 190/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 191/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 192/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 193/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 194/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 195/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 196/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 197/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 198/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 199/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 200/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 201/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 202/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 203/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 204/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 205/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 206/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 207/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 208/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 209/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 210/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 211/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 212/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 213/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 214/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 215/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 216/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 217/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 218/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 219/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 220/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 221/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 222/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 223/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 224/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 225/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 226/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 227/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 228/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 229/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 230/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 231/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 232/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 233/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 234/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 235/300\n",
            "156/156 [==============================] - 0s 977us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 236/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 237/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 238/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 239/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 240/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 241/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 242/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 243/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 244/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 245/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 246/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 247/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 248/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 249/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 250/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 251/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 252/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 253/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 254/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 255/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 256/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 257/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 258/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 259/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 260/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 261/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 262/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 263/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 264/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 265/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 266/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 267/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 268/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 269/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 270/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 271/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 272/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 273/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 274/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 275/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 276/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 277/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 278/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 279/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 280/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 281/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 282/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 283/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 284/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 285/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 286/300\n",
            "156/156 [==============================] - 0s 995us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 287/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 288/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 289/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 290/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 291/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 292/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 293/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 294/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 295/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 296/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 297/300\n",
            "156/156 [==============================] - 0s 997us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 298/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 299/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 300/300\n",
            "156/156 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNHKB4jhdpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "07981369-f447-4bfc-8b10-43712a6d0d08"
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.grid(True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QjkAR4aheUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "cb562d74-d94e-4acc-e523-81aa49539c65"
      },
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.grid(True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}